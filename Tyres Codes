# loading the dataset
ls(E_Data_c)

#Choice Share Calculation
countshare <- function(Xmat, yl, p, target) {
  nchoice <- nrow(Xmat) / p  # Total number of choice tasks
  neffect <- ncol(Xmat)      # Total number of attributes
  Xar <- array(t(Xmat), dim = c(neffect, p, nchoice))  # 3D array for attributes
  yar <- array(yl, dim = c(p, nchoice))  # 2D array for choices
  
  countex <- 0  # Count exposures
  countch <- 0  # Count choices
  
  for (i in 1:nchoice) {  # Loop through each choice task
    X <- t(Xar[,,i])  # Attributes matrix for the task
    y <- yar[,i]      # Choices vector for the task
    
    if (sum(X[, target]) > 0) {  # Check if the level is presented
      countex <- countex + 1  # Increment exposure counter
      if (any(X[y == 1, target] == 1)) {  # Check if the level was chosen
        countch <- countch + 1  # Increment choice counter
      }
    }
  }
  
  return(c(countch / countex, countch, countex))  # Choice share, #choices, #exposures
}


# Function to compute probabilities for a range of attribute-levels
countattribute <- function(Xmat, yl, p, attributerange) {
  out <- matrix(0, nrow = length(attributerange), ncol = 3)  # Initialize output matrix
  counter <- 0
  
  for (r in attributerange) {  # Loop through attribute range
    counter <- counter + 1
    out[counter, ] <- countshare(Xmat, yl, p, r)
  }
  
  rownames(out) <- colnames(Xmat)[attributerange]  # Set row names as attribute names
  colnames(out) <- c('choice share', '# choices', '# exposures')  # Set column names
  
  return(out)
}


# Apply the functions to your dataset
# Use E_Data_c$lgtdata and combine results across respondents
X_all <- do.call(rbind, lapply(E_Data_c$lgtdata, function(respondent) respondent$X))
y_all <- unlist(lapply(E_Data_c$lgtdata, function(respondent) respondent$y))
p <- E_Data_c$p

# Example: Calculate choice probabilities for brands
brand_range <- 2:11  # Assuming columns 2 to 10 correspond to brands
brand_probabilities <- countattribute(X_all, y_all, p, brand_range)

# View results
print(brand_probabilities)

# Example: Calculate choice probabilities for type
Type <- 12:13  # Assuming columns 11 to 12 correspond to brands
Type_probabilities <- countattribute(X_all, y_all, p, Type)

# View results
print(Type_probabilities)

# Example: Calculate choice probabilities for rolling
rolling <- 18:21  # Assuming columns 11 to 12 correspond to brands
rolling_probabilities <- countattribute(X_all, y_all, p, rolling)

# View results
print(rolling_probabilities)

# Example: Calculate choice probabilities for grip
grip <- 22:25  # Assuming columns 11 to 12 correspond to brands
grip_probabilities <- countattribute(X_all, y_all, p, grip)

# View results
print(grip_probabilities)


# Example: Calculate choice probabilities for test
test <- 31:35  # Assuming columns 11 to 12 correspond to brands
test_probabilities <- countattribute(X_all, y_all, p, test)

# View results
print(test_probabilities)


# Example: Calculate choice probabilities for review attributes
review_range <- 26:30  # Assuming columns 25 to 28 correspond to review attributes
review_probabilities <- countattribute(X_all, y_all, p, review_range)

# View results
print(review_probabilities)

# Example: Calculate choice probabilities for longevity attributes
longevity_range <- 14:17  # Assuming columns 13 to 16 correspond to longevity attributes
longevity_probabilities <- countattribute(X_all, y_all, p, longevity_range)

# View results
print(longevity_probabilities)

# Combine all attribute results into one data frame
all_probabilities <- list(
  Brands = brand_probabilities,
  Type = Type_probabilities,
  Rolling = rolling_probabilities,
  Grip = grip_probabilities,
  Test = test_probabilities,
  Review = review_probabilities,
  Longevity = longevity_probabilities
)

# Convert to a single data frame
combined_probabilities <- do.call(rbind, lapply(names(all_probabilities), function(attr) {
  prob_data <- all_probabilities[[attr]]
  data.frame(
    Attribute = attr,
    Level = rownames(prob_data),
    prob_data
  )
}))

# Display combined table
print(combined_probabilities)

write.csv(combined_probabilities, "combined_choice_probabilities.csv", row.names = FALSE)

# Subset brand probabilities
brand_probabilities_long <- data.frame(
  Brand = rownames(brand_probabilities),
  ChoiceShare = brand_probabilities[, "choice share"]
)

# Combine all attribute probabilities into one dataframe
all_attributes_probabilities <- rbind(
  data.frame(Attribute = "Type", Level = rownames(Type_probabilities), Type_probabilities),
  data.frame(Attribute = "Rolling Resistance", Level = rownames(rolling_probabilities), rolling_probabilities),
  data.frame(Attribute = "Grip", Level = rownames(grip_probabilities), grip_probabilities),
  data.frame(Attribute = "Test", Level = rownames(test_probabilities), test_probabilities),
  data.frame(Attribute = "Review", Level = rownames(review_probabilities), review_probabilities),
  data.frame(Attribute = "Longevity", Level = rownames(longevity_probabilities), longevity_probabilities)
)

# Convert to long format for ggplot
library(reshape2)
all_attributes_long <- melt(all_attributes_probabilities, 
                            id.vars = c("Attribute", "Level"), 
                            measure.vars = "choice.share",
                            variable.name = "Metric", 
                            value.name = "Value")

# Load ggplot2
library(ggplot2)

# Create the graph
ggplot(all_attributes_long, aes(x = Level, y = Value, fill = Attribute)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ Attribute, scales = "free_x", ncol = 2) +
  labs(title = "Choice Shares Across Attributes (Excluding Brands)",
       x = "Attribute Levels",
       y = "Choice Share") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  guides(fill = guide_legend(title = "Attributes"))

# Save the graph
ggsave("choice_shares_all_attributes.png", width = 12, height = 8, dpi = 300)


# Load the car package
library(car)
# Fit a linear model using your dataset
lm_model <- lm(price ~ ., data = as.data.frame(E_Data_c$lgtdata[[1]]$X))

# Calculate VIF for each variable in the model
vif_values <- vif(lm_model)

# View the VIF values
print(vif_values)
#Defining Baseline for categorical attributes (brand, review & tes

# Remove baseline attributes from X for all respondents
for (i in seq_along(E_Data_c$lgtdata)) {
  E_Data_c$lgtdata[[i]]$X <- E_Data_c$lgtdata[[i]]$X[, -c(2, 26, 31)]   # Remove 'michelin', 'rev_1star', 'test_1star'
}
# Fit a linear model using your dataset to check for multicollinierity
lm_model <- lm(price ~ ., data = as.data.frame(E_Data_c$lgtdata[[1]]$X))

# Calculate VIF for each variable in the model to check for multicollinierity
vif_values <- vif(lm_model)

# View the VIF values to check for multicollinierity
print(vif_values)


# Combine all y vectors
y_all <- unlist(lapply(E_Data_c$lgtdata, function(respondent_data) respondent_data$y))

# Combine all X matrices
X_all <- do.call(rbind, lapply(E_Data_c$lgtdata, function(respondent_data) respondent_data$X))

# Verify dimensions
print(length(y_all))  # Should be (number of respondents) × (tasks per respondent) = 3652 × 15
print(dim(X_all))     # Should be length(y_all) × number of attributes = 54780 × 32 (after baseline adjustment)

aligned <- nrow(X_all) == length(y_all) * E_Data_c$p
print(aligned)  # Should return TRUE

# Prepare MCMC data
mcmc_data <- list(
  y = y_all,         # Choices vector
  X = X_all,         # Attributes matrix
  p = E_Data_c$p     # Number of alternatives per task
)
# Load bayesm package
library(bayesm)

# Run MCMC estimation
out_mcmc <- rhierMnlRwMixture(
  Data = list(lgtdata = E_Data_c$lgtdata, p = E_Data_c$p),  # Use the full dataset
  Prior = list(ncomp = 1),  # Specify the number of mixture components (1 for homogeneous)
  Mcmc = list(R = 10000, keep = 10)  # Number of iterations and thinning interval
)

# Summarize results
summary(out_mcmc$betadraw)  # Posterior draws for coefficients

# Summarize posterior draws
summary(out_mcmc$betadraw)  # Provides basic statistics for the posterior draws

# Combine all respondent-level draws by averaging over respondents
overall_betadraw <- apply(out_mcmc$betadraw, c(2, 3), mean)  # Average across respondents (dimension 1)

# Compute posterior means and standard deviations across iterations
posterior_summary <- round(cbind(
  Mean = rowMeans(overall_betadraw),  # Mean across iterations for each parameter
  SD = apply(overall_betadraw, 1, sd)  # Standard deviation across iterations for each parameter
), digits = 3)

# Check dimensions
print(dim(posterior_summary))  # Should return 32 × 2
print(posterior_summary)       # Display the summary# Compute posterior means and standard deviations

# Label columns
colnames(posterior_summary) <- c("Mean", "SD")
print(posterior_summary)

# Plot histograms for the first 4 parameters
par(mfrow = c(2, 2))  # Arrange plots in a 2x2 grid
for (i in 1:4) {
  hist(overall_betadraw[i, ], main = paste("Parameter:", rownames(posterior_summary)[i]),
       xlab = "Posterior Draws", breaks = 20, col = "lightblue")
}

price_index <- which(colnames(E_Data_c$lgtdata[[1]]$X) == "price")
print(price_index)  # Should return the column index for "price"

#Introducing Price Constraint
SignRes <- double(ncol(E_Data_c$lgtdata[[1]]$X))  # Initialize with zeros
SignRes[price_index] <- -1  # Constrain the price coefficient to be negative

#######Mixed Logit (Hierarchical Bayesian) Model########

library(bayesm)

out_HB_covariates <- rhierMnlRwMixture(
  Data = list(
    lgtdata = E_Data_c$lgtdata,  # All choice data
    Z = E_Data_c$Z,             # Covariates
    p = E_Data_c$p              # Number of alternatives per task
  ),
  Prior = list(ncomp = 1, SignRes = SignRes),  # Apply sign constraint
  Mcmc = list(R = 40000, keep = 10)           # 40,000 iterations, thinning every 10
)
#Verify Convergence of the Model
windows()
plot(out_HB_covariates$loglike, type = "l", main = "Log-Likelihood Over Iterations",
     xlab = "Iterations", ylab = "Log-Likelihood")

# Get the dimensions of beta draws
print(dim(out_HB_covariates$betadraw))  # Respondents × Attributes × Iterations

# Specify the full file path, including the file name and extension
file_path <- "C:/users/olich/OneDrive/Desktop/Winter 24-25/CSCC/Assignments/out_HB_covariates.RData"

# Save the object to the specified file
save(out_HB_covariates, file = file_path)

# Set burn-in iteration
burn_in <- 1800

# Extract converged iterations (from 18,000 onward)
betadraw_converged <- out_HB_covariates$betadraw[, , (burn_in + 1):dim(out_HB_covariates$betadraw)[3]]

# Check dimensions of the resulting array
print(dim(betadraw_converged))  # Should return Respondents × Attributes × Iterations

# Extract post burn-in samples
betadraw_converged <- out_HB_covariates$betadraw[, , (burn_in + 1):dim(out_HB_covariates$betadraw)[3]]

# Assign dimension names
colnames_converged <- colnames(E_Data_c$lgtdata[[1]]$X)  # Attribute names
dimnames(betadraw_converged) <- list(
  NULL,                 # Respondents
  colnames_converged,   # Attributes
  NULL                  # Iterations
)

# Check dimensions
print(dim(betadraw_converged))  # Should be Respondents × Attributes × (4000 - burn_in)

# Posterior means and standard deviations for each respondent and attribute
posterior_means <- apply(betadraw_converged, c(1, 2), mean)  # Mean across iterations
posterior_sds <- apply(betadraw_converged, c(1, 2), sd)      # SD across iterations

# View respondent-level summaries for the first few respondents
print("Posterior Means (Respondent-Level):")
print(round(posterior_means[1:5, ], 3))  # First 5 respondents
print("Posterior SDs (Respondent-Level):")
print(round(posterior_sds[1:5, ], 3))    # First 5 respondents

# Overall attribute-level summaries (averaged across respondents)
overall_means <- colMeans(posterior_means)
overall_sds <- apply(posterior_means, 2, sd)
posterior_summary <- round(cbind(Mean = overall_means, SD = overall_sds), 3)

# View overall summaries
print("Posterior Summary (Overall):")
print(posterior_summary)

# Log-likelihood trace
plot(out_HB_covariates$loglike, type = "l",
     main = "Log-Likelihood Convergence",
     xlab = "Iteration", ylab = "Log-Likelihood")

# Select attributes of interest ("comfort_type", "sports_type","stand_longevity_km","plus_8thou_km", "fuel_eff_C", "grip_wet_C", "rev_5star","test_4star")
selected_attributes <- c("comfort_type", "sports_type","stand_longevity_km",
                         "plus_8thou_km", "fuel_eff_C", "grip_wet_C", "rev_5star",
                         "test_4star")

# Plot densities for the first respondent
windows()
par(mfrow = c(2, 2))  # Layout for 2x2 plots

for (attr in selected_attributes) {
  plot(density(betadraw_converged[1, attr, ]), 
       main = paste("Density for", attr, "(Respondent 1)"),
       xlab = "Coefficient Value", ylab = "Density")
  abline(v = mean(betadraw_converged[1, attr, ]), col = "red")  # Mean line
  
}
save(betadraw_converged, file = "betadraw_converged.RData")
save(posterior_summary, file = "posterior_summary.RData")

#Combine iterations into a single respondent-level array for betaexchange
betaexchange <- array(
  aperm(betadraw_converged, perm = c(1, 3, 2)),
  dim = c(dim(betadraw_converged)[1] * dim(betadraw_converged)[3], dim(betadraw_converged)[2])
)

# Compute the mean and heterogeneity (standard deviation) across respondents
mpref <- cbind(
  colMeans(betaexchange),                # Mean preferences for each attribute
  apply(betaexchange, 2, sd)             # Heterogeneity (SD) of preferences
)

# Assign column names
colnames(mpref) <- c("Mean Preference", "Heterogeneity")
rownames(mpref) <- colnames(E_Data_c$lgtdata[[1]]$X)

# View the results
print(round(mpref, digits = 3))

# Compute mean preferences from the Homogeneous model
aggregate_means <- apply(out_mcmc$betadraw, 2, mean)  # Homogeneous model posterior means

# Combine respondent-level and Homogeneous-level means for comparison
comparison <- round(cbind(
  Respondent_Level_Mean = mpref[, "Mean Preference"],  # From individual-level model
  Aggregate_Mean = aggregate_means                    # From homogeneous model
), digits = 2)

# View the comparison
print(comparison)

# Set attribute labels after excluding baseline levels
colnames(betaexchange) <- colnames(E_Data_c$lgtdata[[1]]$X)

# Visualize preference heterogeneity
windows()
par(mfcol = c(2, 2))

# Plot density for "price"
plot(density(betaexchange[, "price"]), 
     main = "Price Preference Distribution", 
     xlab = "Price Coefficient")

# Plot density for "comfort_type"
plot(density(betaexchange[, "comfort_type"]), 
     main = "comfort_type Preference Distribution", 
     xlab = "comfort_type Coefficient")

# Plot density for "Longevity"
plot(density(betaexchange[, "plus_8thou_km"]), 
     main = "plus_8thou_km Preference Distribution", 
     xlab = "plus_8thou_km Coefficient")

# Plot density for "rolling"
plot(density(betaexchange[, "fuel_eff_F"]), 
     main = "fuel_eff_F Preference Distribution", 
     xlab = "fuel_eff_F Coefficient")

# Plot scatter plot between two attributes (e.g., "price" vs. "rev_5star")
smoothScatter(betaexchange[, "price"], betaexchange[, "rev_5star"], 
              xlab = "Price Coefficient", 
              ylab = "rev_5star Coefficient", 
              main = "Price vs. rev_5star Preferences")

# Add another scatter plot (e.g., "price" vs. "test_5star")
smoothScatter(betaexchange[, "price"], betaexchange[, "test_5star"], 
              xlab = "Price Coefficient", 
              ylab = "test_5star Coefficient", 
              main = "Price vs. test_5star Preferences")

# Open a new plotting window
windows()
par(mfcol = c(4, 4))  # Create a 4x4 grid of plots

# Loop through all attributes in `betaexchange`
for (i in 1:ncol(betaexchange)) {
  # Plot density for each attribute
  plot(density(betaexchange[, i]), 
       main = colnames(betaexchange)[i], 
       xlab = "Coefficient Value", 
       ylab = "Density")
}

# Open a new plotting window
windows()
par(mfrow = c(3, 3))  # Create a 3x3 grid of scatter plots

# Define pairs of attributes to compare
attribute_pairs <- list(
  c("price", "continental"),
  c("price", "goodyear"),
  c("price", "stand_longevity_km"),
  c("price", "plus_8thou_km"),
  c("continental", "pirelli"),
  c("grip_wet_B", "fuel_eff_B"),
  c("stand_longevity_km", "plus_4thou_km"),
  c("rev_5star", "test_5star")
)

# Generate scatter plots for the selected pairs
for (pair in attribute_pairs) {
  smoothScatter(betaexchange[, pair[1]], betaexchange[, pair[2]], 
                xlab = pair[1], 
                ylab = pair[2], 
                main = paste(pair[1], "vs.", pair[2]))
}

# Define alternatives with attributes
alt1 <- c(1, 0, 0, 0, 0, 0, 0, 0, 0,  # Brand: continental
          1, 0,                       # Type: comfort_type
          0, 0, 0, 1,                 # Longevity: plus_8thou_km
          0, 0, 1, 0,                 # Rolling Resistance: fuel_eff_E
          0, 1, 0, 0,                 # Grip: grip_wet_C
          0, 1, 0, 0,                 # Review: rev_3star
          0, 0, 0, 1)                 # Test: test_5star

alt2 <- c(0, 0, 0, 0, 1, 0, 0, 0, 0,  # Brand: kleber
          1, 0,                       # Type: comfort_type
          0, 1, 0, 0,                 # Longevity: stand_longevity_km
          0, 1, 0, 0,                 # Rolling Resistance: fuel_eff_C
          0, 0, 0, 1,                 # Grip: grip_wet_E
          0, 0, 1, 0,                 # Review: rev_4star
          0, 0, 0, 1)                 # Test: test_5star

alt3 <- c(0, 0, 1, 0, 0, 0, 0, 0, 0,  # Brand: bridgestone
          0, 1,                       # Type: sports_type
          0, 0, 1, 0,                 # Longevity: plus_4thou_km
          1, 0, 0, 0,                 # Rolling Resistance: fuel_eff_B
          0, 0, 1, 0,                 # Grip: grip_wet_D
          0, 1, 0, 0,                 # Review: rev_3star
          0, 0, 0, 1)                 # Test: test_5star

alt4 <- c(0, 0, 0, 0, 0, 0, 0, 0, 1,  # Brand: low_price-brand
          1, 0,                       # Type: comfort_type
          0, 0, 0, 1,                 # Longevity: plus_8thou_km
          0, 0, 1, 0,                 # Rolling Resistance: fuel_eff_E
          0, 0, 0, 1,                 # Grip: grip_wet_E
          0, 0, 0, 1,                 # Review: rev_5star
          0, 0, 0, 1)                 # Test: test_5star

alt5 <- c(0, 0, 0, 1, 0, 0, 0, 0, 0,  # Brand: low_price-brand
          1, 0,                       # Type: comfort_type
          1, 0, 0, 0,                 # Longevity: min_4thou_km
          0, 0, 1, 0,                 # Rolling Resistance: fuel_eff_E
          1, 0, 0, 0,                 # Grip: grip_wet_A
          0, 0, 0, 1,                 # Review: rev_5star
          0, 1, 0, 0)                 # Test: test_3star

# Define the outside option
outside_option <- rep(0, length(alt1))

# Combine the alternatives into a choice set
choice_set <- rbind(alt1, alt2, alt3, alt4, alt5, outside_option)
# Add a placeholder `price` column at the first position
choice_set <- cbind(price = rep(0, nrow(choice_set)), choice_set)

# Define column names for the modified choice set
colnames(choice_set) <- c(
  "price", "continental", "goodyear", "bridgestone", "pirelli", "kleber",
  "bfgoodrich", "firestone", "hankook", "low_price-brand", "comfort_type",
  "sports_type", "min_4thou_km", "stand_longevity_km", "plus_4thou_km",
  "plus_8thou_km", "fuel_eff_B", "fuel_eff_C", "fuel_eff_E", "fuel_eff_F",
  "grip_wet_B", "grip_wet_C", "grip_wet_E", "grip_wet_F", "rev_2star",
  "rev_3star", "rev_4star", "rev_5star", "test_2star", "test_3star",
  "test_4star", "test_5star"
)
# Inspect the choice set
print(choice_set)


# Set burn-in period (from your mixed logit model setup)
burn_in <- 1800

# Extract post-burn-in samples
betadraw_converged <- out_HB_covariates$betadraw[, , (burn_in + 1):dim(out_HB_covariates$betadraw)[3]]

# Compute the average betas across iterations (mean over the third dimension)
betadraw_avg <- apply(betadraw_converged, c(2, 3), mean)

# Set row names for `betadraw_avg` to match attribute names
rownames(betadraw_avg) <- colnames(E_Data_c$lgtdata[[1]]$X


# Define price levels
prices <- seq(3, 10, by = 0.5)  # Example price levels from 3 to 10 with 0.5 increments

# Append price levels to the choice set for each price level
choiceset_with_price <- lapply(prices, function(price) {
  choice_set_with_price <- choice_set
  choice_set_with_price[, "price"] <- price  # Assign price value to the first column
  return(choice_set_with_price)
})

# Inspect the first choice set with appended price
print(choiceset_with_price[[1]])

#Price Demand Calculation
compute_probabilities <- function(prices, choiceset_with_price, betadraw_avg) {
  # Initialize a list to store probabilities
  probabilities_list <- list()
  
  # Iterate over each price level
  for (i in seq_along(prices)) {
    cat("Processing price level:", prices[i], "\n")
    
    # Extract the choice set for the current price level
    current_choice_set <- choiceset_with_price[[i]]
    
    # Calculate utilities for each alternative
    utilities <- current_choice_set %*% betadraw_avg  # Matrix multiplication
    
    # Exponentiate the utilities
    exp_utilities <- exp(utilities)
    
    # Normalize by summing over rows (choices)
    probabilities <- exp_utilities / rowSums(exp_utilities)
    
    # Store the probabilities
    probabilities_list[[i]] <- probabilities
  }
  
  return(probabilities_list)
}

# Compute probabilities for all price levels
probabilities <- compute_probabilities(prices, choiceset_with_price, betadraw_avg)

# Inspect the first set of probabilities
print(probabilities[[1]])  # View probabilities for the first price level
print(dim(probabilities))



# Function to compute market shares
compute_market_shares <- function(choice_set, betadraw) {
  # Initialize a matrix to store market shares
  num_alternatives <- nrow(choice_set)
  num_respondents <- dim(betadraw)[1]
  
  # Matrix to store probabilities for each respondent and alternative
  probabilities <- matrix(0, nrow = num_respondents, ncol = num_alternatives)
  
  # Iterate over respondents
  for (i in 1:num_respondents) {
    # Compute utilities for each alternative for the current respondent
    utilities <- choice_set %*% betadraw[i, ]
    
    # Compute exponential utilities
    exp_utilities <- exp(utilities)
    
    # Normalize probabilities (divide by the sum of exp_utilities)
    probabilities[i, ] <- exp_utilities / sum(exp_utilities)
  }
  
  # Aggregate probabilities to get average market shares
  market_shares <- colMeans(probabilities)
  
  return(market_shares)
}

# Remove price column from choice set
choice_set_no_price <- choice_set[, -which(colnames(choice_set) == "price")]

# Compute market shares using the betadraws
market_shares <- compute_market_shares(choice_set_no_price, betadraw_avg)

# Print the market shares
print("Market Shares (Average across respondents):")
print(market_shares)

# Optionally, plot the market shares
barplot(
  market_shares,
  names.arg = rownames(choice_set),
  main = "Market Shares Without Price Levels",
  xlab = "Alternatives",
  ylab = "Market Share",
  col = "skyblue"
)


# Confirm files were saved
print(paste("Mixed logit model saved to:", file_path_hb))
print(paste("Homogeneous model saved to:", file_path_mc))
